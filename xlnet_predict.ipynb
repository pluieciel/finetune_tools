{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "xlnet predict.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pluieciel/finetune_tools/blob/master/xlnet_predict.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "fnOHnctkG6kW"
      },
      "source": [
        "# Mount Google Drive\n",
        "fp.write(s.encode('utf8'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2mBzLdrdzodb"
      },
      "source": [
        "## Setup\n",
        "Install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "hRHRPImGUth7",
        "colab": {}
      },
      "source": [
        "! pip install sentencepiece\n",
        "! pip install pymupdf\n",
        "! pip install pdfminer.six"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NmOt93v9c1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfWPKpQXUnHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r predict_input\n",
        "#!rm -r predict_input.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_VJ6JnGDVOCl",
        "colab_type": "text"
      },
      "source": [
        "pdf to sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "robWSgWyO9xe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import shutil,os\n",
        "import sys\n",
        "sys.path.insert(1, '/content/drive/My Drive/xlnet')\n",
        "import predict_tools\n",
        "\n",
        "input_dir='/content/'\n",
        "txt_sentence_dir='/content/predict_input/test/neg/'\n",
        "\n",
        "r, d, f = next(os.walk(input_dir))\n",
        "doc_list=[file for file in f if file.rfind('.pdf') != -1]\n",
        "\n",
        "os.makedirs(txt_sentence_dir)\n",
        "os.mkdir('/content/predict_input/test/pos/')\n",
        "os.mkdir('/content/predict_input/test/other/')\n",
        "\n",
        "for num, doc in enumerate(doc_list):\n",
        "    input_pdf='/content/'+doc\n",
        "    predict_tools.pdftosentence(input_pdf,txt_sentence_dir,num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "jDP-IaVuPC-z"
      },
      "source": [
        "## Define Variables\n",
        "Define all the dirs: data, xlnet scripts & pretrained model. \n",
        "If you would like to save models then you can authenticate a GCP account and use that for the OUTPUT_DIR & CHECKPOINT_DIR - you will need a large amount storage to fix these models. \n",
        "\n",
        "Alternatively it is easy to integrate a google drive account, checkout this guide for [I/O in colab](https://colab.research.google.com/notebooks/io.ipynb) but rememeber these will take up a large amount of storage. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUJJU_TVdcbg",
        "colab_type": "text"
      },
      "source": [
        "##Predict\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6RDZq070aaqG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! unzip predict_input.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BfCbStlxVV9I",
        "colab_type": "text"
      },
      "source": [
        "sentences to tsv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CEMuT6LU0avg",
        "colab": {}
      },
      "source": [
        "predict_command = \"python drive/My\\ Drive/xlnet/run_classifier_3.py \\\n",
        "  --do_predict=True \\\n",
        "  --predict_dir=predict_out3 \\\n",
        "  --task_name=transcript_classification \\\n",
        "  --overwrite_data=True \\\n",
        "  --data_dir=predict_input \\\n",
        "  --output_dir=out \\\n",
        "  --model_dir=drive/My\\ Drive/xlmodel \\\n",
        "  --uncased=False \\\n",
        "  --spiece_model_file=drive/My\\ Drive/xlmodel/spiece.model \\\n",
        "  --model_config_path=drive/My\\ Drive/xlmodel/xlnet_config.json \\\n",
        "  --init_checkpoint=drive/My\\ Drive/xlmodel/model.ckpt-2200 \\\n",
        "  --predict_ckpt=drive/My\\ Drive/xlmodel/model.ckpt-2200 \\\n",
        "  --max_seq_length=64\"\n",
        "\n",
        "! {predict_command}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_TSwFpSVSCp",
        "colab_type": "text"
      },
      "source": [
        "tsv to highlighted pdf"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6hTdYW0TXQe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tsv='/content/predict_out3/transcript_classification.tsv'\n",
        "\n",
        "for num, doc in enumerate(doc_list):\n",
        "    input_pdf='/content/'+doc\n",
        "    outdoc='/content/'+doc[0:-4]+'_MH2.pdf'\n",
        "\n",
        "    predict_tools.addhighlight_3class(input_pdf,outdoc,predict_tools.tsvtolist_3class(tsv,txt_sentence_dir,num))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}